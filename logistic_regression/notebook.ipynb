{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGqYy8SJkzxu",
        "colab_type": "text"
      },
      "source": [
        "# **Logistic Regression**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UDKZhMjn5a_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8abcc274-dd47-45a9-aff2-3f4ced6cac33"
      },
      "source": [
        "# Getting python's version\n",
        "\n",
        "import sys\n",
        "\n",
        "print(sys.version)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Apr 18 2020, 01:56:04) \n",
            "[GCC 8.4.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOp_7hmxlE-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "471a1b88-996b-4de4-92b6-5d67a1882c09"
      },
      "source": [
        "# Importing numpy package\n",
        "import numpy as np\n",
        "\n",
        "print(np.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.18.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZggcIbPojq9",
        "colab_type": "text"
      },
      "source": [
        "## **Table of Contents**\n",
        "\n",
        "\n",
        "\n",
        "1.   Mean normalization\n",
        "2.   Sigmoid\n",
        "3.   Hypothesis\n",
        "4.   Cost function\n",
        "5.   Gradient descent *(regularized)*\n",
        "6.   Predict function\n",
        "7.   Testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y8DredzlqTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mean normalization\n",
        "def normalize(X):\n",
        "    # Not normalizing 1's (constant term)\n",
        "    X_ones = np.ones((len(X), 1)).reshape(1, -1)\n",
        "\n",
        "    # Calculating mean along each column(axis=0)\n",
        "    _mean = np.mean(X, axis=0)\n",
        "\n",
        "    # Calculating standard deviation along each column(axis=0)\n",
        "    _std = np.std(X, axis=0)\n",
        "\n",
        "    # Calculating Z-score\n",
        "    z_score = np.divide((X - _mean), _std)\n",
        "\n",
        "    X = np.concatenate((X_ones.T, z_score), axis=1)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GeTHvAHluYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWcJA8mMLdKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hypothesis\n",
        "def hypothesis(X, theta):\n",
        "    z = np.matmul(X, theta)\n",
        "    return sigmoid(z)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDMDbYs9lxLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cost function\n",
        "def cost(X, y, theta):\n",
        "    # Lenght of our samples set, X\n",
        "    m = len(X)\n",
        "    h = hypothesis(X, theta)\n",
        "\n",
        "    J = - (1 / m) * (np.matmul(y.T, np.log(h)) + np.matmul((1 - y).T, np.log(1 - h)))\n",
        "\n",
        "    return J"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxNVMFV8l3tZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gradient descent\n",
        "def gradient_descent(X, y, theta, alpha, _lambda, num_of_iters):\n",
        "    # Lenght of our samples set, X\n",
        "    m = len(X)\n",
        "\n",
        "    # Initializing column vector, J_history where all elements assigned to 0,\n",
        "    # while iterating we will fill these values with those iterations cost function's value\n",
        "    J_history = np.zeros((num_of_iters, 1))\n",
        "\n",
        "    # Gradient Descent Algorithm Implementation\n",
        "    for i in range(num_of_iters):\n",
        "        h = hypothesis(X, theta)\n",
        "\n",
        "        # Regularization parameter\n",
        "        regularization_param = (_lambda / m) * theta\n",
        "\n",
        "        # Regularizing all coefficients. This vectorized version of gradient descent\n",
        "        tmp_1 = theta - (alpha * ((1 / m) * ((np.matmul(X.T, (h - y)) + regularization_param))))\n",
        "\n",
        "        # We should NOT regularize the parameter theta_zero\n",
        "        tmp_2 = theta[0] - (alpha * (1 / m) * (np.matmul((h - y).T, X[:, 0])))\n",
        "\n",
        "        theta = tmp_1\n",
        "        theta[0] = tmp_2\n",
        "\n",
        "        J_history[i] = cost(X, y, theta)\n",
        "\n",
        "    return (theta, J_history)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUCdJFajl8Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict\n",
        "def predict(X, theta, threshold=0.5):\n",
        "    # This is our probability vector\n",
        "    prob_vect = hypothesis(X, theta)\n",
        "\n",
        "    # Using list comprehension to check if probabilty >= threshold then 1 else 0\n",
        "    result = [1 if p >= threshold else 0 for vect in prob_vect for p in vect]\n",
        "    result = np.array(result).reshape(1, -1)\n",
        "    return result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zqSPEf_mA0p",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuzpPtJLm6BO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fc306a5b-05f7-42f3-90da-2a5a0e50f449"
      },
      "source": [
        "# Using functions that we built (with Gradient Descent approach)\n",
        "\n",
        "X = np.array([[1, 1], [2.1, 5], [7, 1.9], [1, 4]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "theta = np.array([[0], [0], [0]])  # initializing our parameters\n",
        "\n",
        "X =  normalize(X)\n",
        "\n",
        "theta, _ = gradient_descent(X, Y, theta, 0.001, 0, 100000)\n",
        "\n",
        "print(f'Coefficients: {theta[1:]}')\n",
        "print(f'Intercept: {theta[0]}')\n",
        "\n",
        "# Predictions\n",
        "print(predict(X, theta, threshold=0.5))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: [[4.74392777]\n",
            " [3.03639371]]\n",
            "Intercept: [-0.45952852]\n",
            "[[0 1 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfVEjXuJmXt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6dc0918e-7ca2-45eb-8642-1c5dbb806e1c"
      },
      "source": [
        "# Using sklearn package\n",
        "\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(f'Sklearn version: {sklearn.__version__}')\n",
        "\n",
        "X = np.array([[1, 1], [2.1, 5], [7, 1.9], [1, 4]])\n",
        "Y = np.array([0, 1, 1, 0])\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "model = linear_model.LogisticRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "print(f'Coefficient: {model.coef_}')\n",
        "print(f'Intercept: {model.intercept_}')\n",
        "\n",
        "# Predictions\n",
        "print(model.predict(X))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sklearn version: 0.22.2.post1\n",
            "Coefficient: [[0.79914584 0.41044679]]\n",
            "Intercept: [0.00036492]\n",
            "[0 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoBxTTAjnjnV",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    }
  ]
}